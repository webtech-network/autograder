import json
from datetime import datetime
from openai import OpenAI
import os
from utils.path import Path
client = OpenAI(api_key=f"{os.getenv('OPENAI_API_KEY')}")
def get_key_value(list, name):
    """

    :param list:
    :param name:
    :return:
    """
    for item in list:
        for key in item:
            if key == name:
                return item[key]


def generate_md(base, bonus, penalty,final_score,author,feedback_file="feedback.json"):
    """
    Generate a Markdown report for autograding feedback.
    Takes dictionaries for base, bonus, and penalty with keys `passed` and `failed` containing test names.

    :param base: Dictionary containing passed and failed tests for base checks.
    :param bonus: Dictionary containing passed and failed tests for bonus checks.
    :param author: String containing author name.
    :param penalty: Dictionary containing passed and failed tests for penalty checks.
    :param final_score: The final calculated score (provided as a parameter).
    :param feedback_file: Path to the JSON file containing test-specific feedback (default is "tests_feedback.json").
    :return: A Markdown formatted string with feedback.
    """

    path = Path(__file__, "..")

    # Load feedback data from the JSON file
    with open(path.getFilePath(feedback_file), "r", encoding="utf-8") as file:
        tests_feedback = json.load(file)
    passed = True if final_score >= 70 else False
    # Initialize feedback
    feedback = f"# ğŸ§ª RelatÃ³rio de AvaliaÃ§Ã£o â€“ Autograder HTML - {author}\n\n"
    feedback += f"**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
    feedback += f"**Nota Final:** `{format(final_score,'.2f')}/100`\n"
    feedback += f"**Status:** {'âœ… Aprovado' if passed else 'âŒ Reprovado'}\n\n"
    feedback += "---\n"

    # Base Feedback (Requisitos ObrigatÃ³rios)
    feedback += "## âœ… Requisitos ObrigatÃ³rios (80%)\n"
    if len(base["failed"]) == 0:
        feedback += "- Todos os requisitos bÃ¡sicos foram atendidos. Excelente trabalho!\n"
    else:
        feedback += f"- Foram encontrados `{len(base['failed'])}` problemas nos requisitos obrigatÃ³rios. Veja abaixo os testes que falharam:\n"
        for test_name in base["failed"]:
            # Get the feedback from the JSON structure based on pass/fail
            passed_feedback = get_key_value(tests_feedback["base_tests"],test_name)[1]  # Failed feedback
            feedback += f"  - âš ï¸ **Falhou no teste**: `{test_name}`\n"
            feedback += f"    - **Melhoria sugerida**: {passed_feedback}\n"

    # Bonus Feedback
    feedback += "\n## â­ Itens de Destaque (20%)\n"
    if len(bonus["passed"]) > 0:
        feedback += f"- VocÃª conquistou `{len(bonus['passed'])}` bÃ´nus! Excelente trabalho nos detalhes adicionais!\n"
        for passed_test in bonus["passed"]:
            # Get the feedback for passed bonus tests
            passed_feedback = get_key_value(tests_feedback["bonus_tests"],passed_test)[0]  # Failed feedback
            feedback += f"  - ğŸŒŸ **Testes bÃ´nus passados**: `{passed_test}`\n"
            feedback += f"    - {passed_feedback}\n"
    else:
        feedback += "- Nenhum item bÃ´nus foi identificado. Tente adicionar mais estilo e complexidade ao seu cÃ³digo nas prÃ³ximas tentativas!\n"

    # Penalty Feedback
    feedback += "\n## âŒ Problemas Detectados (Descontos de atÃ© -30%)\n"
    if len(penalty["passed"]) > 0 :
        feedback += f"- Foram encontrados `{len(penalty['passed'])}` problemas que acarretam descontos. Veja abaixo os testes penalizados:\n"
        for failed_test in penalty["passed"]:
            # Get the feedback for failed penalty tests
            failed_feedback = get_key_value(tests_feedback["penalty_tests"],failed_test)[0]  # Failed feedback
            feedback += f"  - âš ï¸ **Falhou no teste de penalidade**: `{failed_test}`\n"
            feedback += f"    - **CorreÃ§Ã£o sugerida**: {failed_feedback}\n"
    else:
        feedback += "- Nenhuma infraÃ§Ã£o grave foi detectada. Muito bom nesse aspecto!\n"

    feedback += "\n---\n"
    feedback += "Continue praticando e caprichando no cÃ³digo. Cada detalhe conta! ğŸ’ª\n"

    return feedback

def generate_ai_md(code,base,bonus,penalty,final_score,author):
    candidate_code = """\
    def add(a, b):
        return a + b
    """

    test_results = {
        "base": base,
        "bonus": bonus,
        "penalty":penalty,
        "score": final_score
    }

    system_prompt = (
        "VocÃª Ã© um revisor de cÃ³digo especialista. VocÃª acabou de receber a soluÃ§Ã£o de um candidato "
        "para um desafio de cÃ³digo. Seu trabalho Ã© fornecer um feedback amigÃ¡vel, humano e motivador com base nos "
        "testes de unidade que passaram e falharam. VocÃª elogiarÃ¡ o que Ã© bom, destacarÃ¡ problemas de forma gentil "
        "e incentivarÃ¡ o candidato a melhorar. Seu tom Ã© casual, empÃ¡tico, humano e construtivo. "
        "VocÃª deve retornar respostas formatadas em markdown, isso Ã© obrigatÃ³rio. "
        "A resposta deve ser apenas em direÃ§Ã£o ao candidato, sem mencionar o revisor ou o sistema."
    )

    user_prompt = f"""
    Nome do aluno: {author}
    ### ğŸ§ª CÃ³digo submetido:

    ```python
    {code}
    ```

    ### ğŸ“Š Resultados dos testes:

    **Testes base:**  
    {test_results['base']}

    **Testes bÃ´nus:**  
    {test_results['bonus']}

    **Testes de penalidade:**  
    {test_results['penalty']}

    **PontuaÃ§Ã£o final:** {test_results['score']}/100

    Por favor, forneÃ§a um feedback amigÃ¡vel, humano e motivador.
    A resposta deve ser apenas em direÃ§Ã£o ao candidato, sem mencionar o revisor ou o sistema.
    ForneÃ§a toda a resposta em uma estrutura bem feita em markdown com elementos de tÃ­tulos, indentaÃ§Ã£o e listas.Markdown Ã© obrigatÃ³rio.
    """

    response = client.chat.completions.create(model="gpt-3.5-turbo",
                                              messages=[
                                                  {"role": "system", "content": system_prompt},
                                                  {"role": "user", "content": user_prompt}
                                              ],
                                              temperature=0.7)
    feedback = response.choices[0].message.content
    return feedback

